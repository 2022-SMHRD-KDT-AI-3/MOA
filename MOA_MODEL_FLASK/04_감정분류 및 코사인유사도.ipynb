{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42620b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense,Dropout, Conv1D,GlobalMaxPooling1D,concatenate\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a94dcab",
   "metadata": {},
   "source": [
    "## 데이터 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e9c71f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df= pd.read_excel('./감성대화말뭉치(원시데이터)_Training.xlsx')\n",
    "df2 = pd.read_excel(\"./감성대화말뭉치(원시데이터)_Validation.xlsx\")\n",
    "df3 = pd.read_excel(\"./감성대화말뭉치(최종데이터)_Training.xlsx\")\n",
    "df4 = pd.read_excel(\"./감성대화말뭉치(최종데이터)_Validation.xlsx\")\n",
    "df5 = pd.concat([df,df2,df3,df4],axis=0)\n",
    "df5 = df5.drop(columns=['사람문장4','시스템응답4','신체질환'])\n",
    "df5 = df5.drop_duplicates().reset_index()\n",
    "df5 = df5.drop(columns=['index'])\n",
    "df5 = df5.drop(4)\n",
    "df5 = df5.reset_index().drop(columns='index')\n",
    "df5 = df5.fillna(\"\").drop_duplicates()\n",
    "np.unique(df5['감정_대분류'],return_counts=True)\n",
    "emo_dic = {\n",
    "    \"기쁨\" : 0,    \"기쁨 \" : 0,    \"분노\" : 1,    \"불안\" : 2,    \"불안 \" : 2,    \"슬픔\" : 3,\n",
    "}\n",
    "env_dic={\n",
    "    \"가족관계\" : 0 ,    \n",
    "    \"건강\" : 1,    \n",
    "    '건강, 죽음': 1 ,    \n",
    "    '대인관계': 2 , \n",
    "    \"대인관계(부부, 자녀)\" : 2 ,\n",
    "    \"연애, 결혼, 출산\" : 3 ,    \n",
    "    \"재정\" : 4 ,    \"재정, 은퇴, 노후준비\" : 4 , \n",
    "    \"직장, 업무 스트레스\" : 5 ,  \n",
    "    \"진로, 취업, 직장\" : 5 ,    \n",
    "    \"학교폭력/따돌림\" : 6 ,    \n",
    "    \"학업 및 진로\" : 5 \n",
    "}\n",
    "\n",
    "\n",
    "df5['상황키워드'] = df5['상황키워드'].map(env_dic)\n",
    "df5['감정_대분류'] = df5['감정_대분류'].map(emo_dic)\n",
    "\n",
    "sen1 = df5['사람문장1']\n",
    "sen2 = df5['사람문장2']\n",
    "sen3 = df5['사람문장3']\n",
    "full_sen = []\n",
    "for i in range(0,len(df5)):\n",
    "    txt = str(sen1[i])+str(sen2[i])+str(sen3[i])\n",
    "    full_sen.append(txt)\n",
    "df5['전체문장'] = full_sen\n",
    "df5.to_excel(\"8만여개의 감성데이터.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "08c17193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>연령</th>\n",
       "      <th>상황키워드</th>\n",
       "      <th>감정_대분류</th>\n",
       "      <th>사람문장1</th>\n",
       "      <th>시스템응답1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>노년</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>당뇨랑 합병증 때문에 먹어야 할 약이 열 가지가 넘어가니까 스트레스야.</td>\n",
       "      <td>약이 많아서 힘드시겠어요. 줄이기 위해서는 어떻게 해야 하나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>노년</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>너무 안 좋은데 하기 싫고 하자니 비싸네.</td>\n",
       "      <td>그렇군요. 그래도 필요하다면 해야겠죠?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>노년</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>대인관계에 혼란을 느껴.</td>\n",
       "      <td>무슨 일이 있으셧나요?. 어떤 일 때문에 그러세요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>노년</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>몸이 안좋으데 이제 어떻게 살아가야 하는지 . 많이 혼란스럽네.</td>\n",
       "      <td>걱정이 많으시군요. 다른 방법은 없을까요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>노년</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>수술해 본 적이 없는데 신장 이식 수술을 받아야 한다고 해서 무서워.</td>\n",
       "      <td>많이 두려우실것 같아요. 그래도 좋은 결과 있기를 바랍니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24247</th>\n",
       "      <td>중년</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>우리 가족 건강은 내가 책임지고 있어. 왜냐면 내가 건강하거든.</td>\n",
       "      <td>기분이 좋으시겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24248</th>\n",
       "      <td>중년</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>오늘 회사에서 새 프로젝트를 성사시켰어.</td>\n",
       "      <td>좋은 결과를 얻어 기쁘시겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24249</th>\n",
       "      <td>중년</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>은퇴 후에 취미생활하면서 나한테 투자하고 있어. 너무 좋아.</td>\n",
       "      <td>기쁘시겠어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24250</th>\n",
       "      <td>중년</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>나는 우리 부서가 올해 최대 실적을 거둘 거로 생각하고 있어.</td>\n",
       "      <td>그렇게 생각하게 된 계기가 있나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24251</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>모아야 자기소개 해줘</td>\n",
       "      <td>안녕하세요 저는 사용자의 감정을 분석하는 인공지능 챗봇서비스 모아입니다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24252 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        연령  상황키워드  감정_대분류                                    사람문장1  \\\n",
       "0       노년      1     2.0  당뇨랑 합병증 때문에 먹어야 할 약이 열 가지가 넘어가니까 스트레스야.   \n",
       "1       노년      4     2.0                  너무 안 좋은데 하기 싫고 하자니 비싸네.   \n",
       "2       노년      2     2.0                            대인관계에 혼란을 느껴.   \n",
       "3       노년      1     2.0      몸이 안좋으데 이제 어떻게 살아가야 하는지 . 많이 혼란스럽네.   \n",
       "4       노년      1     2.0   수술해 본 적이 없는데 신장 이식 수술을 받아야 한다고 해서 무서워.   \n",
       "...    ...    ...     ...                                      ...   \n",
       "24247   중년      1     0.0      우리 가족 건강은 내가 책임지고 있어. 왜냐면 내가 건강하거든.   \n",
       "24248   중년      5     0.0                   오늘 회사에서 새 프로젝트를 성사시켰어.   \n",
       "24249   중년      4     0.0        은퇴 후에 취미생활하면서 나한테 투자하고 있어. 너무 좋아.   \n",
       "24250   중년      5     0.0       나는 우리 부서가 올해 최대 실적을 거둘 거로 생각하고 있어.   \n",
       "24251  NaN      2     0.0                              모아야 자기소개 해줘   \n",
       "\n",
       "                                         시스템응답1  \n",
       "0           약이 많아서 힘드시겠어요. 줄이기 위해서는 어떻게 해야 하나요?  \n",
       "1                         그렇군요. 그래도 필요하다면 해야겠죠?  \n",
       "2                  무슨 일이 있으셧나요?. 어떤 일 때문에 그러세요?  \n",
       "3                       걱정이 많으시군요. 다른 방법은 없을까요?  \n",
       "4              많이 두려우실것 같아요. 그래도 좋은 결과 있기를 바랍니다  \n",
       "...                                         ...  \n",
       "24247                               기분이 좋으시겠어요.  \n",
       "24248                         좋은 결과를 얻어 기쁘시겠어요.  \n",
       "24249                                   기쁘시겠어요.  \n",
       "24250                       그렇게 생각하게 된 계기가 있나요?  \n",
       "24251  안녕하세요 저는 사용자의 감정을 분석하는 인공지능 챗봇서비스 모아입니다.  \n",
       "\n",
       "[24252 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.read_excel(\"./0620.xlsx\")\n",
    "result['상황키워드'] = result['상황키워드'].map(env_dic)\n",
    "result['감정_대분류'] = result['감정_대분류'].map(emo_dic)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e318200f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6], dtype=int64),\n",
       " array([ 4742, 12546, 20874,  7617, 12136, 18977,  5046], dtype=int64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df5.상황키워드,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a1a1ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81938, 81938)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df5['전체문장'].dropna().to_list()\n",
    "labels = df5['감정_대분류'].to_list()\n",
    "len(features), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb16ca4",
   "metadata": {},
   "source": [
    "### 감성대화 말뭉치 데이터 \n",
    "- 4개 병합 \n",
    "- 감정mapping\n",
    "- 사람문장1,2,3  합치기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aeb874",
   "metadata": {},
   "source": [
    "### 1. 훈련데이터, 정답데이터 추출( 사람문장1만 사용 )\n",
    "- 훈련데이터 : 전체문장 \n",
    "- 정답데이터 : 감정_대분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daadffac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81938, 81938)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = pd.read_excel(\"./8만여개의 감성데이터.xlsx\")\n",
    "features = df5['전체문장'].dropna().to_list()\n",
    "labels = df5['감정_대분류'].to_list()\n",
    "len(features), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b1a77",
   "metadata": {},
   "source": [
    "### 단어사전 구축 \n",
    "- text_to_word_sequence : 132,667개\n",
    "- Okt : 55,692개\n",
    "- komoran : 18,274개\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "### 1-3 전처리\n",
    "- word_index : 총 단어 수 \n",
    "- MAX_SEQ_LEN : 문장 길이 고정 \n",
    "- padded_seqs : 문장 길이 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8ce232c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "corpus = [okt.morphs(x) for x in features]\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "sequence = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "len_txt = [len(x) for x in sequence]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "MAX_SEQ_LEN = 100  ##패딩 50\n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequence, maxlen=MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb19ad8",
   "metadata": {},
   "source": [
    "# 1-4 CNN을 이용한 감정 분류 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df4045a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 100, 128)     7128704     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 100, 128)     0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 98, 128)      49280       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 97, 128)      65664       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 96, 128)      82048       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 128)         0           ['conv1d[0][0]']                 \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Global  (None, 128)         0           ['conv1d_1[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_2 (Global  (None, 128)         0           ['conv1d_2[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 384)          0           ['global_max_pooling1d[0][0]',   \n",
      "                                                                  'global_max_pooling1d_1[0][0]', \n",
      "                                                                  'global_max_pooling1d_2[0][0]'] \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          49280       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " logits (Dense)                 (None, 4)            516         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4)            20          ['logits[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,375,512\n",
      "Trainable params: 7,375,512\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "2868/2868 [==============================] - 34s 10ms/step - loss: 0.7760 - accuracy: 0.6920 - val_loss: 0.5054 - val_accuracy: 0.8238\n",
      "Epoch 2/200\n",
      "2868/2868 [==============================] - 27s 10ms/step - loss: 0.5564 - accuracy: 0.8039 - val_loss: 0.4028 - val_accuracy: 0.8658\n",
      "Epoch 3/200\n",
      "2868/2868 [==============================] - 28s 10ms/step - loss: 0.4641 - accuracy: 0.8416 - val_loss: 0.3084 - val_accuracy: 0.8997\n",
      "Epoch 4/200\n",
      "2868/2868 [==============================] - 26s 9ms/step - loss: 0.3935 - accuracy: 0.8693 - val_loss: 0.2648 - val_accuracy: 0.9162\n",
      "Epoch 5/200\n",
      "2868/2868 [==============================] - 26s 9ms/step - loss: 0.3335 - accuracy: 0.8909 - val_loss: 0.2086 - val_accuracy: 0.9350\n",
      "Epoch 6/200\n",
      "2868/2868 [==============================] - 26s 9ms/step - loss: 0.2922 - accuracy: 0.9036 - val_loss: 0.1662 - val_accuracy: 0.9476\n",
      "Epoch 7/200\n",
      "2868/2868 [==============================] - 26s 9ms/step - loss: 0.2492 - accuracy: 0.9199 - val_loss: 0.1307 - val_accuracy: 0.9609\n",
      "Epoch 8/200\n",
      "2868/2868 [==============================] - 26s 9ms/step - loss: 0.2225 - accuracy: 0.9285 - val_loss: 0.1206 - val_accuracy: 0.9617\n",
      "Epoch 9/200\n",
      "2868/2868 [==============================] - 27s 9ms/step - loss: 0.1990 - accuracy: 0.9357 - val_loss: 0.0993 - val_accuracy: 0.9706\n",
      "Epoch 10/200\n",
      "2868/2868 [==============================] - 27s 9ms/step - loss: 0.1802 - accuracy: 0.9416 - val_loss: 0.0918 - val_accuracy: 0.9717\n",
      "Epoch 11/200\n",
      "2868/2868 [==============================] - 27s 9ms/step - loss: 0.1619 - accuracy: 0.9472 - val_loss: 0.0704 - val_accuracy: 0.9774\n",
      "Epoch 12/200\n",
      "2868/2868 [==============================] - 26s 9ms/step - loss: 0.1449 - accuracy: 0.9525 - val_loss: 0.0711 - val_accuracy: 0.9758\n",
      "Epoch 13/200\n",
      "2868/2868 [==============================] - 26s 9ms/step - loss: 0.1370 - accuracy: 0.9558 - val_loss: 0.0552 - val_accuracy: 0.9819\n",
      "Epoch 14/200\n",
      "2868/2868 [==============================] - 25s 9ms/step - loss: 0.1260 - accuracy: 0.9590 - val_loss: 0.0545 - val_accuracy: 0.9836\n",
      "Epoch 15/200\n",
      "2868/2868 [==============================] - 27s 9ms/step - loss: 0.1158 - accuracy: 0.9621 - val_loss: 0.0481 - val_accuracy: 0.9846\n",
      "Epoch 16/200\n",
      "2868/2868 [==============================] - 27s 9ms/step - loss: 0.1081 - accuracy: 0.9652 - val_loss: 0.0478 - val_accuracy: 0.9846\n",
      "Epoch 17/200\n",
      "2868/2868 [==============================] - 26s 9ms/step - loss: 0.0999 - accuracy: 0.9674 - val_loss: 0.0368 - val_accuracy: 0.9890\n",
      "Epoch 18/200\n",
      "2868/2868 [==============================] - 27s 9ms/step - loss: 0.0951 - accuracy: 0.9691 - val_loss: 0.0293 - val_accuracy: 0.9912\n",
      "Epoch 19/200\n",
      "2868/2868 [==============================] - 27s 9ms/step - loss: 0.0886 - accuracy: 0.9704 - val_loss: 0.0318 - val_accuracy: 0.9896\n",
      "Epoch 20/200\n",
      "2868/2868 [==============================] - 27s 9ms/step - loss: 0.0816 - accuracy: 0.9741 - val_loss: 0.0272 - val_accuracy: 0.9906\n",
      "Epoch 21/200\n",
      "2868/2868 [==============================] - 27s 9ms/step - loss: 0.0787 - accuracy: 0.9741 - val_loss: 0.0256 - val_accuracy: 0.9926\n",
      "Epoch 22/200\n",
      "2868/2868 [==============================] - 26s 9ms/step - loss: 0.0762 - accuracy: 0.9752 - val_loss: 0.0239 - val_accuracy: 0.9927\n",
      "Epoch 23/200\n",
      "2868/2868 [==============================] - 26s 9ms/step - loss: 0.0727 - accuracy: 0.9768 - val_loss: 0.0254 - val_accuracy: 0.9923\n",
      "Epoch 24/200\n",
      "2868/2868 [==============================] - 26s 9ms/step - loss: 0.0692 - accuracy: 0.9781 - val_loss: 0.0206 - val_accuracy: 0.9933\n",
      "Epoch 25/200\n",
      "2868/2868 [==============================] - 26s 9ms/step - loss: 0.0649 - accuracy: 0.9791 - val_loss: 0.0223 - val_accuracy: 0.9934\n",
      "Epoch 26/200\n",
      "2868/2868 [==============================] - 27s 9ms/step - loss: 0.0648 - accuracy: 0.9792 - val_loss: 0.0145 - val_accuracy: 0.9951\n",
      "Epoch 27/200\n",
      "2868/2868 [==============================] - 26s 9ms/step - loss: 0.0618 - accuracy: 0.9802 - val_loss: 0.0208 - val_accuracy: 0.9937\n",
      "Epoch 28/200\n",
      "2868/2868 [==============================] - 26s 9ms/step - loss: 0.0564 - accuracy: 0.9819 - val_loss: 0.0196 - val_accuracy: 0.9941\n",
      "Epoch 29/200\n",
      "2868/2868 [==============================] - 27s 9ms/step - loss: 0.0582 - accuracy: 0.9819 - val_loss: 0.0178 - val_accuracy: 0.9944\n",
      "410/410 [==============================] - 2s 3ms/step - loss: 0.0142 - accuracy: 0.9951\n",
      "Accuracy :  99.51177835464478\n",
      "loss :  0.014156375080347061\n"
     ]
    }
   ],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((padded_seqs,labels))\n",
    "ds = ds.shuffle(len(features))\n",
    "train_size = int(len(padded_seqs)*0.7)\n",
    "val_size = int(len(padded_seqs)*0.2)\n",
    "test_size = int(len(padded_seqs)*0.1)\n",
    "train_ds = ds.take(train_size).batch(20)\n",
    "val_ds = ds.skip(train_size).take(val_size).batch(20)\n",
    "test_ds = ds.skip(train_size+val_size).take(test_size).batch(20)\n",
    "\n",
    "dropout_prob = 0.5\n",
    "EMB_SIZE = 128\n",
    "EPOCH=200\n",
    "VOCAB_SIZE = len(word_index)+1\n",
    "\n",
    "input_layer = Input(shape=(MAX_SEQ_LEN,))\n",
    "embedding_layer = Embedding(VOCAB_SIZE, EMB_SIZE, input_length = MAX_SEQ_LEN)(input_layer)\n",
    "dropout_emb = Dropout(rate=dropout_prob)(embedding_layer)\n",
    "\n",
    "conv1 = Conv1D(filters=128,   kernel_size = 3, padding=\"valid\",  activation = tf.nn.relu)(dropout_emb)\n",
    "pool1 = GlobalMaxPooling1D()(conv1)\n",
    "\n",
    "conv2 = Conv1D(filters=128, kernel_size = 4, padding=\"valid\", activation = tf.nn.relu)(dropout_emb)\n",
    "poo2 = GlobalMaxPooling1D()(conv2)\n",
    "\n",
    "conv3 = Conv1D(filters=128, kernel_size = 5, padding=\"valid\", activation = tf.nn.relu)(dropout_emb)\n",
    "poo3 = GlobalMaxPooling1D()(conv3)\n",
    "\n",
    "# 3,4,5-gram 이후 합치기 \n",
    "concat = concatenate([pool1,poo2,poo3])\n",
    "\n",
    "hidden = Dense(128,activation=tf.nn.relu)(concat)\n",
    "dropout_hidden = Dropout(rate=dropout_prob)(hidden)\n",
    "logits = Dense(4,name=\"logits\")(dropout_hidden)\n",
    "predictions = Dense(4, activation=tf.nn.softmax)(logits)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs = predictions)\n",
    "model.compile(optimizer=\"adam\",\n",
    "             loss=\"sparse_categorical_crossentropy\",\n",
    "             metrics=\"accuracy\")\n",
    "model.summary()\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('best-emo-model.h5')\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3,\n",
    "                                                 restore_best_weights=True)\n",
    "\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=EPOCH,callbacks=[checkpoint_cb,early_stopping_cb])\n",
    "\n",
    "# 모델 평가\n",
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy : \",accuracy*100)\n",
    "print(\"loss : \",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125615c2",
   "metadata": {},
   "source": [
    "# 1-5 CNN을 이용한 상황 분류 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a99eafcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81938, 81938)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = pd.read_excel(\"./8만여개의 감성데이터.xlsx\")\n",
    "features = df5['전체문장'].dropna().to_list()\n",
    "labels2 = df5['상황키워드'].to_list()\n",
    "len(features), len(labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afdb2b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2868/2868 [==============================] - 34s 10ms/step - loss: 0.8969 - accuracy: 0.6974 - val_loss: 0.5206 - val_accuracy: 0.8250\n",
      "Epoch 2/15\n",
      " 716/2868 [======>.......................] - ETA: 18s - loss: 0.6141 - accuracy: 0.8017"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1228\\1702491264.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m                                                  restore_best_weights=True)\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0menv_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_cb2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearly_stopping_cb2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m# 모델 평가\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep5\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deep5\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2454\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1861\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((padded_seqs,labels2))\n",
    "ds = ds.shuffle(len(features))\n",
    "train_size = int(len(padded_seqs)*0.7)\n",
    "val_size = int(len(padded_seqs)*0.2)\n",
    "test_size = int(len(padded_seqs)*0.1)\n",
    "train_ds = ds.take(train_size).batch(20)\n",
    "val_ds = ds.skip(train_size).take(val_size).batch(20)\n",
    "test_ds = ds.skip(train_size+val_size).take(test_size).batch(20)\n",
    "\n",
    "dropout_prob = 0.5\n",
    "EMB_SIZE = 128\n",
    "EPOCH=15\n",
    "VOCAB_SIZE = len(word_index)+1\n",
    "\n",
    "input_layer = Input(shape=(MAX_SEQ_LEN,))\n",
    "embedding_layer = Embedding(VOCAB_SIZE, EMB_SIZE, input_length = MAX_SEQ_LEN)(input_layer)\n",
    "dropout_emb = Dropout(rate=dropout_prob)(embedding_layer)\n",
    "\n",
    "conv1 = Conv1D(filters=128,   kernel_size = 3, padding=\"valid\",  activation = tf.nn.relu)(dropout_emb)\n",
    "pool1 = GlobalMaxPooling1D()(conv1)\n",
    "\n",
    "conv2 = Conv1D(filters=128, kernel_size = 4, padding=\"valid\", activation = tf.nn.relu)(dropout_emb)\n",
    "poo2 = GlobalMaxPooling1D()(conv2)\n",
    "\n",
    "conv3 = Conv1D(filters=128, kernel_size = 5, padding=\"valid\", activation = tf.nn.relu)(dropout_emb)\n",
    "poo3 = GlobalMaxPooling1D()(conv3)\n",
    "\n",
    "# 3,4,5-gram 이후 합치기 \n",
    "concat = concatenate([pool1,poo2,poo3])\n",
    "\n",
    "hidden = Dense(128,activation=tf.nn.relu)(concat)\n",
    "dropout_hidden = Dropout(rate=dropout_prob)(hidden)\n",
    "logits = Dense(7,name=\"logits\")(dropout_hidden)\n",
    "predictions = Dense(7, activation=tf.nn.softmax)(logits)\n",
    "\n",
    "env_model = Model(inputs=input_layer, outputs = predictions)\n",
    "env_model.compile(optimizer=\"adam\",\n",
    "             loss=\"sparse_categorical_crossentropy\",\n",
    "             metrics=\"accuracy\")\n",
    "\n",
    "checkpoint_cb2 = keras.callbacks.ModelCheckpoint('best-env-model.h5')\n",
    "early_stopping_cb2 = keras.callbacks.EarlyStopping(patience=3,\n",
    "                                                 restore_best_weights=True)\n",
    "\n",
    "env_model.fit(train_ds, validation_data=val_ds, epochs=EPOCH, callbacks=[checkpoint_cb2,early_stopping_cb2])\n",
    "\n",
    "# 모델 평가\n",
    "loss, accuracy = env_model.evaluate(test_ds)\n",
    "print(\"Accuracy : \",accuracy*100)\n",
    "print(\"loss : \",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1196e4",
   "metadata": {},
   "source": [
    "### 1-6. 랜덤 사용자 문항에 대한 감정 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "173d36a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['과중한 업무가 끝나서 이제 쉬려나 했는데 다시 업무가 부여가 돼서 지치네.']\n",
      "[['과중', '한', '업무', '가', '끝나서', '이제', '쉬려나', '했는데', '다시', '업무', '가', '부여', '가', '돼서', '지치네', '.']]\n",
      "[[5618, 27, 160, 4, 2757, 60, 29475, 55, 173, 160, 4, 11465, 4, 313, 4581, 1]]\n",
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "   5618    27   160     4  2757    60 29475    55   173   160     4 11465\n",
      "      4   313  4581     1]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1228\\4146704119.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_s1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0memo_model_predict_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_s1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0memo_model_predict_class_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memo_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_s1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0memo_model_predict_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_s1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "emo_list = [\"기쁨\",\"분노\",\"불안\",\"슬픔\"]   # 감정클래스 리스트 \n",
    "\n",
    "import random as rd    \n",
    "num = rd.randrange(0,100)  # 데이터 프레임 행 중에 난수를 하나 생성\n",
    "\n",
    "s1 = [result.iloc[20004,:]['사람문장1']]\n",
    "cor_s1 = [okt.morphs(x) for x in s1]\n",
    "seq_s1 = tokenizer.texts_to_sequences(cor_s1)\n",
    "pad_s1 = preprocessing.sequence.pad_sequences(seq_s1,maxlen=MAX_SEQ_LEN)\n",
    "\n",
    "print(s1)\n",
    "print(cor_s1)\n",
    "print(seq_s1)\n",
    "print(pad_s1)\n",
    "\n",
    "emo_model_predict_proba = model.predict(pad_s1)[0]\n",
    "emo_model_predict_class_index = emo_list[np.argmax(model.predict(pad_s1)[0])]\n",
    "emo_model_predict_index = np.argmax(model.predict(pad_s1)[0])\n",
    "print(\"감정 예측 점수 : \",emo_model_predict_proba)\n",
    "print(\"감정 예측 클래스 : \",emo_model_predict_class_index)\n",
    "print(\"상황 예측 인덱스 : \",emo_model_predict_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc7edf0",
   "metadata": {},
   "source": [
    "### 1-7. 랜덤 사용자 문항에 대한 상황 분류 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05b02bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "상황 예측 점수 :  [8.41859961e-04 1.81968901e-02 6.04156494e-01 3.32210981e-03\n",
      " 5.99822868e-03 3.67372006e-01 1.12350746e-04]\n",
      "상황 예측 클래스 :  대인관계\n",
      "상황 예측 인덱스 :  2\n"
     ]
    }
   ],
   "source": [
    "env_list = [\"가족관계\", \"건강\",\"대인관계\",\"연애, 결혼, 출산\",\"재정\",\"직장\",\"학교폭력/따돌림\"]\n",
    "\n",
    "s1 = [result.iloc[9656,:]['사람문장1']]\n",
    "cor_s1 = [okt.morphs(x) for x in s1]\n",
    "seq_s1 = tokenizer.texts_to_sequences(cor_s1)\n",
    "pad_s1 = preprocessing.sequence.pad_sequences(seq_s1,maxlen=MAX_SEQ_LEN)\n",
    "\n",
    "\n",
    "env_model_predict_proba = env_model.predict(pad_s1)[0]\n",
    "env_model_predict_class = env_list[np.argmax(env_model.predict(pad_s1)[0])]\n",
    "env_model_predict_index = np.argmax(env_model.predict(pad_s1)[0])\n",
    "print(\"상황 예측 점수 : \",env_model_predict_proba)\n",
    "print(\"상황 예측 클래스 : \",env_model_predict_class)\n",
    "print(\"상황 예측 인덱스 : \",env_model_predict_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7336a43f",
   "metadata": {},
   "source": [
    "### 유사도 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfe5b22c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emo_model_predict_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1228\\2158840691.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memo_env_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0memo_model_predict_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0menv_model_predict_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_Answer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mmoa_answer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madaquate_answer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'emo_model_predict_index' is not defined"
     ]
    }
   ],
   "source": [
    "# 해당되는 감정과 카테고리 행을 추출하는 함수 \n",
    "def emo_env_request(df, emotion, enviroment):\n",
    "    condition1 = (df['감정_대분류']==emotion)\n",
    "    condition2 = (df['상황키워드']==enviroment)\n",
    "    Q_Answers = df[condition1 & condition2]\n",
    "    return Q_Answers['사람문장1'].to_list() , Q_Answers['시스템응답1'].to_list()\n",
    "\n",
    "# 감정문장 리스트 중 가장 유사한 문장을 찾아 인덱스를 반환하는 함수\n",
    "def cosine_Answer(txt,df_list):\n",
    "    cos_sim_list = [] \n",
    "    ####### 텍스트 유사도 측정 ######\n",
    "    # 문장 벡터화 하기(사전 만들기)\n",
    "    for i in df_list:\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        sentences = (txt,i)\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
    "        ### 코사인 유사도 ###\n",
    "        cos_similar = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "        cos_sim_list.append(cos_similar[0][0])\n",
    "    # 가장 유사한 문장이 있는 인덱스와 가장 유사한 문장을 반환 \n",
    "    return np.argmax(cos_sim_list), df_list[np.argmax(cos_sim_list)]\n",
    "\n",
    "\n",
    "# 코사인 함수의 인덱스를 이용해 가장 적절한 응답을 찾는 함수 \n",
    "def adaquate_answer(df, idx):\n",
    "    return df[idx]\n",
    "\n",
    "request, response = emo_env_request(result,emo_model_predict_index,env_model_predict_index)\n",
    "idx, answer = cosine_Answer(s1[0],request)\n",
    "moa_answer = adaquate_answer(response,idx)\n",
    "print(s1[0])\n",
    "print(answer)\n",
    "print(moa_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae47986",
   "metadata": {},
   "source": [
    "# 2. 입력 최종 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cb9fa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장을 입력해주세요 : 로또에 당첨이 되었어\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1228\\3653092488.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpad_s1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_s1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_SEQ_LEN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0memo_model_predict_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_s1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0memo_model_predict_class_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memo_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_s1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0memo_model_predict_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_s1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "emo_list = [\"기쁨\",\"분노\",\"불안\",\"슬픔\"]  \n",
    "env_list = [\"가족관계\", \"건강\",\"대인관계\",\"연애, 결혼, 출산\",\"재정\",\"직장\",\"학교폭력/따돌림\"]\n",
    "\n",
    "s1 = [input(\"문장을 입력해주세요 : \")]\n",
    "cor_s1 = [okt.morphs(x) for x in s1]\n",
    "seq_s1 = tokenizer.texts_to_sequences(cor_s1)\n",
    "pad_s1 = preprocessing.sequence.pad_sequences(seq_s1,maxlen=MAX_SEQ_LEN)\n",
    "\n",
    "emo_model_predict_proba = model.predict(pad_s1)[0]\n",
    "emo_model_predict_class_index = emo_list[np.argmax(model.predict(pad_s1)[0])]\n",
    "emo_model_predict_index = np.argmax(model.predict(pad_s1)[0])\n",
    "\n",
    "env_model_predict_proba = env_model.predict(pad_s1)[0]\n",
    "env_model_predict_class = env_list[np.argmax(env_model.predict(pad_s1)[0])]\n",
    "env_model_predict_index = np.argmax(env_model.predict(pad_s1)[0])\n",
    "\n",
    "\n",
    "request, response = emo_env_request(result,emo_model_predict_index,env_model_predict_index)\n",
    "idx, answer = cosine_Answer(s1[0],request)\n",
    "moa_answer = adaquate_answer(response,idx)\n",
    "\n",
    "print(\"입력문 : \",s1[0])\n",
    "print(\"유사문 : \", answer)\n",
    "print(\"응답문 : \", moa_answer)\n",
    "print(\"감정 : \",emo_model_predict_class_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe4a70",
   "metadata": {},
   "source": [
    "# FLASK 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4b9b45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://172.30.1.59:5000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.30.1.53 - - [20/Jun/2022 11:09:18] \"POST /review_model HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.30.1.59 - - [20/Jun/2022 12:03:57] \"POST /review_model HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.30.1.59 - - [20/Jun/2022 12:11:25] \"POST /review_model HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.30.1.59 - - [20/Jun/2022 14:11:52] \"POST /review_model HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.30.1.59 - - [20/Jun/2022 14:12:13] \"POST /review_model HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.30.1.59 - - [20/Jun/2022 14:13:19] \"POST /review_model HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-20 15:39:01,952] ERROR in app: Exception on /review_model [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smhrd\\anaconda3\\envs\\deep5\\lib\\site-packages\\flask\\app.py\", line 2077, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\smhrd\\anaconda3\\envs\\deep5\\lib\\site-packages\\flask\\app.py\", line 1525, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\smhrd\\anaconda3\\envs\\deep5\\lib\\site-packages\\flask\\app.py\", line 1523, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\smhrd\\anaconda3\\envs\\deep5\\lib\\site-packages\\flask\\app.py\", line 1509, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"C:\\Users\\smhrd\\AppData\\Local\\Temp\\ipykernel_1228\\2360835942.py\", line 22, in index\n",
      "    result = model(num1)\n",
      "  File \"C:\\Users\\smhrd\\AppData\\Local\\Temp\\ipykernel_1228\\2423664400.py\", line 66, in model\n",
      "    idx, answer = cosine_Answer(s1[0],request)\n",
      "  File \"C:\\Users\\smhrd\\AppData\\Local\\Temp\\ipykernel_1228\\2158840691.py\", line 21, in cosine_Answer\n",
      "    return np.argmax(cos_sim_list), df_list[np.argmax(cos_sim_list)]\n",
      "  File \"<__array_function__ internals>\", line 6, in argmax\n",
      "  File \"C:\\Users\\smhrd\\anaconda3\\envs\\deep5\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 1195, in argmax\n",
      "    return _wrapfunc(a, 'argmax', axis=axis, out=out)\n",
      "  File \"C:\\Users\\smhrd\\anaconda3\\envs\\deep5\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 54, in _wrapfunc\n",
      "    return _wrapit(obj, method, *args, **kwds)\n",
      "  File \"C:\\Users\\smhrd\\anaconda3\\envs\\deep5\\lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 43, in _wrapit\n",
      "    result = getattr(asarray(obj), method)(*args, **kwds)\n",
      "ValueError: attempt to get argmax of an empty sequence\n",
      "172.30.1.59 - - [20/Jun/2022 15:39:01] \"POST /review_model HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.30.1.59 - - [20/Jun/2022 15:39:33] \"POST /review_model HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.30.1.59 - - [20/Jun/2022 15:39:45] \"POST /review_model HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.30.1.59 - - [20/Jun/2022 15:45:17] \"POST /review_model HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "from flask import request, redirect\n",
    "\n",
    "app = Flask(__name__) \n",
    "\n",
    "@app.route('/review_model', methods=['GET','POST'])\n",
    "def index():     \n",
    "       \n",
    "    if request.method == 'POST':\n",
    "        #안드로이드에서 getParams()메소드 안에 작성한 \n",
    "        # parsms.put(\"num1\", \"데이터1\");\n",
    "        \n",
    "        # 의 key값인 num1, num2를 통해서 데이터 접근하여 변수에 저장\n",
    "        num1 = str(request.form['message'])\n",
    "        \n",
    "        #num2 = int(request.form['num2'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        #딥러닝 모델을 함수로 구현한 후 결과값을 return하여 result변수에 저장\n",
    "        #딥러닝 모델은 아래 Cell에 만들 것\n",
    "        result = model(num1)\n",
    "\n",
    "    #결과값 리턴하면 안드로이드 스튜디오 StringRequest 안에 있는 onResponse()로 값 전달\n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #ip주소 변경하세요\n",
    "    app.run(host='172.30.1.59', port='5000') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a460e",
   "metadata": {},
   "source": [
    "# ★딥러닝 모델 코드를 아래 함수 안에 넣고 결과값을 return 문에 작성할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2b7f251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense,Dropout, Conv1D,GlobalMaxPooling1D,concatenate\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from konlpy.tag import Okt, Komoran\n",
    "\n",
    "\n",
    "# def emo_env_request(df, emotion, enviroment):\n",
    "#     condition1 = (df['감정_대분류']==emotion)\n",
    "#     condition2 = (df['상황키워드']==enviroment)\n",
    "#     Q_Answers = df[condition1 & condition2]\n",
    "#     return Q_Answers['사람문장1'].to_list() , Q_Answers['시스템응답1'].to_list()\n",
    "\n",
    "# # 감정문장 리스트 중 가장 유사한 문장을 찾아 인덱스를 반환하는 함수\n",
    "# def cosine_Answer(txt,df_list):\n",
    "#     cos_sim_list = [] \n",
    "#     ####### 텍스트 유사도 측정 ######\n",
    "#     # 문장 벡터화 하기(사전 만들기)\n",
    "#     for i in df_list:\n",
    "#         tfidf_vectorizer = TfidfVectorizer()\n",
    "#         sentences = (txt,i)\n",
    "#         tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
    "#         ### 코사인 유사도 ###\n",
    "#         cos_similar = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "#         cos_sim_list.append(cos_similar[0][0])\n",
    "#     # 가장 유사한 문장이 있는 인덱스와 가장 유사한 문장을 반환 \n",
    "#     return np.argmax(cos_sim_list), df_list[np.argmax(cos_sim_list)]\n",
    "\n",
    "\n",
    "# # 코사인 함수의 인덱스를 이용해 가장 적절한 응답을 찾는 함수 \n",
    "# def adaquate_answer(df, idx):\n",
    "#     return df[idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#머신러닝 모델함수\n",
    "def model(num1):\n",
    "    emo_model = keras.models.load_model(\"./best-emo-model.h5\")\n",
    "    env_model = keras.models.load_model(\"./best-env-model.h5\")\n",
    "    #모델구현\n",
    "    s1 = [num1]\n",
    "    cor_s1 = [okt.morphs(x) for x in s1]\n",
    "    seq_s1 = tokenizer.texts_to_sequences(cor_s1)\n",
    "    pad_s1 = preprocessing.sequence.pad_sequences(seq_s1,maxlen=100)\n",
    "\n",
    "    emo_model_predict_proba = emo_model.predict(pad_s1)[0]\n",
    "    emo_model_predict_class_index = emo_list[np.argmax(emo_model.predict(pad_s1)[0])]\n",
    "    emo_model_predict_index = np.argmax(emo_model.predict(pad_s1)[0])\n",
    "    \n",
    "\n",
    "\n",
    "    env_model_predict_proba = env_model.predict(pad_s1)[0]\n",
    "    env_model_predict_class = env_list[np.argmax(env_model.predict(pad_s1)[0])]\n",
    "    env_model_predict_index = np.argmax(env_model.predict(pad_s1)[0])\n",
    "\n",
    "    request, response = emo_env_request(result,emo_model_predict_index,env_model_predict_index)\n",
    "    idx, answer = cosine_Answer(s1[0],request)\n",
    "    moa_answer = adaquate_answer(response,idx)\n",
    "\n",
    "    total_result = {\"msg\" : moa_answer, \"msg_emo\" : emo_model_predict_class_index}\n",
    "     \n",
    "    return total_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c0817e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'msg': '건강에 대해 고민이 있으시네요. 좀 더 말씀해 보시겠어요?', 'msg_emo': '슬픔'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model('건강이 좋지 않아')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdb92ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 :  2022-06-18 15:18:52.025769\n",
      "현재 날짜 :  2022-06-18\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "print(\"현재 : \", now)\n",
    "print(\"현재 날짜 : \", now.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4dc2ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa427fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pymysql.connect(host='project-db-stu.ddns.net', user='MOA', passoword=\"1234\", db=\"MOA\", charset='utf8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
